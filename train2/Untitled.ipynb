{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e1a47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e5316528",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8093b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(\"I am Vaishali. I am from India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "529feaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "am\n",
      "Vaishali\n",
      ".\n",
      "I\n",
      "am\n",
      "from\n",
      "India\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6893c9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am Vaishali. I am from India\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c59aee3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator at 0x161d18820>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaee3802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "am\n",
      "Vaishali\n",
      ".\n",
      "I\n",
      "am\n",
      "from\n",
      "India\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    for word in sent:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1c804d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/vaishalilalit/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a23b0dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a0c1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1c6360d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am Vaishali.', 'I am from India']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(\"I am Vaishali. I am from India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1800321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'Vaishali', '.', 'I', 'am', 'from', 'India']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"I am Vaishali. I am from India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99faad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp1=spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6ddbfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp1(\"I am Vaishali. I am from India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c6c06c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "am\n",
      "Vaishali\n",
      ".\n",
      "I\n",
      "am\n",
      "from\n",
      "India\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07a601f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E057] Stepped slices not supported in Span objects. Try: `list(tokens)[start:stop:step]` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m doc[::\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/tokens/doc.pyx:500\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.__getitem__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/util.py:1268\u001b[0m, in \u001b[0;36mnormalize_slice\u001b[0;34m(length, start, stop, step)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize_slice\u001b[39m(\n\u001b[1;32m   1265\u001b[0m     length: \u001b[38;5;28mint\u001b[39m, start: \u001b[38;5;28mint\u001b[39m, stop: \u001b[38;5;28mint\u001b[39m, step: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m step \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m-> 1268\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE057)\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1270\u001b[0m         start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: [E057] Stepped slices not supported in Span objects. Try: `list(tokens)[start:stop:step]` instead."
     ]
    }
   ],
   "source": [
    "doc[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b86e0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '_bulk_merge',\n",
       " '_context',\n",
       " '_get_array_attrs',\n",
       " '_realloc',\n",
       " '_vector',\n",
       " '_vector_norm',\n",
       " 'cats',\n",
       " 'char_span',\n",
       " 'copy',\n",
       " 'count_by',\n",
       " 'doc',\n",
       " 'ents',\n",
       " 'extend_tensor',\n",
       " 'from_array',\n",
       " 'from_bytes',\n",
       " 'from_dict',\n",
       " 'from_disk',\n",
       " 'from_docs',\n",
       " 'from_json',\n",
       " 'get_extension',\n",
       " 'get_lca_matrix',\n",
       " 'has_annotation',\n",
       " 'has_extension',\n",
       " 'has_unknown_spaces',\n",
       " 'has_vector',\n",
       " 'is_nered',\n",
       " 'is_parsed',\n",
       " 'is_sentenced',\n",
       " 'is_tagged',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'mem',\n",
       " 'noun_chunks',\n",
       " 'noun_chunks_iterator',\n",
       " 'remove_extension',\n",
       " 'retokenize',\n",
       " 'sentiment',\n",
       " 'sents',\n",
       " 'set_ents',\n",
       " 'set_extension',\n",
       " 'similarity',\n",
       " 'spans',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'to_array',\n",
       " 'to_bytes',\n",
       " 'to_dict',\n",
       " 'to_disk',\n",
       " 'to_json',\n",
       " 'to_utf8_array',\n",
       " 'user_data',\n",
       " 'user_hooks',\n",
       " 'user_span_hooks',\n",
       " 'user_token_hooks',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7be4ddd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[http://www.data.gov/, http://www.science, http://data.gov.uk/., http://www3.norc.org/gss+website/, http://www.europeansocialsurvey.org/.]\n"
     ]
    }
   ],
   "source": [
    "text='''\n",
    "Look for data to help you address the question. Governments are good\n",
    "sources because data from public research is often freely available. Good\n",
    "places to start include http://www.data.gov/, and http://www.science.\n",
    "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
    "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
    "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
    "'''\n",
    "\n",
    "# TODO: Write code here\n",
    "doc=nlp(text)\n",
    "urls=[]\n",
    "for token in doc:\n",
    "    if token.like_url:\n",
    "        urls.append(token)\n",
    "print(urls)\n",
    "# Hint: token has an attribute that can be used to detect a url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62a3cd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two $\n",
      "500 €\n"
     ]
    }
   ],
   "source": [
    "transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n",
    "\n",
    "# TODO: Write code here\n",
    "doc=nlp(transactions)\n",
    "for token in doc:\n",
    "    if token.like_num and (doc[(token.i+1)].is_currency):\n",
    "#             print(\"Hi\")\n",
    "            print(token,doc[token.i+1])\n",
    "# Hint: Use token.i for the index of a token and token.is_currency for currency symbol detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb40dcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x15187bbf0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x15187bb90>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1515961f0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x151513850>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x150ea8e50>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x151597680>)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4576f788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
